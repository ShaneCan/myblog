---
title: Recent Gains from reading research papers[Nov 17th]
author: Tianxiong Zhang
date: '2023-11-17'
slug: recent-gains-from-reading-research-papers-Nov-17th
categories:
  - Essay
tags:
  - Deep Learning
subtitle: ''
summary: ''
authors: []
lastmod: '2023-11-17T20:38:32+08:00'
featured: no
draft: no
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/CpkOjOcXdUY)'
  focal_point: ""
  placement: 2
  preview_only: false
projects: []
summary: "Daily Paper Reading "
---
#### [1] Zhang H, Xie C, Toriya H, et al. Vehicle Localization in a Completed City-Scale 3D Scene Using Aerial Images and an On-Board Stereo Camera[J]. Remote Sensing, 2023, 15(15): 3871.

Navigation in autonomous driving cars currently relies heavily on high-precision maps. However, the production of high-precision maps is both complex and expensive, posing challenges for commercialization. Therefore, the paper proposes a global positioning system using low-precision urban-scale 3D scene maps reconstructed by UAVs to optimize the visual positioning of vehicles. To address the differences in image information due to different aerial and ground viewpoints, the paper introduces a wall complementary algorithm based on building geometries to refine the city-scale 3D scene. The paper also develops a 3D-to-3D feature alignment algorithm to determine the vehicle position by combining the optimized city-scale 3D scene with the local scene generated by the on-board stereo camera.

**Note1:**
The innovation of the paper is that it proposes a SLAM system that fuses bird's-eye view and ground view while reconstructing a 3D large-scale scene model. The UAV vision sensor provides an aerial view of the city. This aerial view is used to reconstruct a previous 3D large scene model at the commercial district scale. The ground vision sensor consists of two pairs of stereo cameras mounted on the vehicle to capture a ground view. This ground view is used to localize the vehicle within the larger scene.

**Note2:**
The construction of high precision maps within the apron has been conceptualized before, and the limiting point is that the reconstruction requires taking a large number of photographs of different angles within the actual aircraft stand, which is difficult to achieve. The reconstruction and experimental validation in this thesis was also not realized using actual scenes, but a computer graphics (CG) simulator. The scene acquisition and validation in the simulator provides ideas for the construction of high precision maps within the apron.